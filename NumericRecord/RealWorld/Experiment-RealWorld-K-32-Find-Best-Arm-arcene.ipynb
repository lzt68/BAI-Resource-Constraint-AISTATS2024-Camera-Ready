{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb67c899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T10:06:23.038002Z",
     "iopub.status.busy": "2023-03-25T10:06:23.037255Z",
     "iopub.status.idle": "2023-03-25T10:06:25.498333Z",
     "shell.execute_reply": "2023-03-25T10:06:25.496230Z"
    },
    "papermill": {
     "duration": 2.471258,
     "end_time": "2023-03-25T10:06:25.502689",
     "exception": false,
     "start_time": "2023-03-25T10:06:23.031431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of label -1 is 112\n",
      "number of label 1 is 88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from agent import *\n",
    "from env import Env_Classifier_CrossEntropy\n",
    "from utils import Experiment_Classiflier\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "from sklearn.linear_model import LogisticRegression  # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "from sklearn.svm import SVC  # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn.ensemble import RandomForestClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.ensemble import AdaBoostClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "\n",
    "dataset_ = pd.read_csv(\"./Arcene.csv\")\n",
    "data = dataset_[dataset_.columns[:-1]].values\n",
    "target = dataset_[dataset_.columns[-1]].values\n",
    "dataset = dict()\n",
    "dataset[\"data\"] = data\n",
    "dataset[\"target\"] = target\n",
    "\n",
    "index = dataset[\"target\"]==-1\n",
    "print(f\"number of label -1 is {np.sum(index)}\")\n",
    "index = dataset[\"target\"]==1\n",
    "print(f\"number of label 1 is {np.sum(index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1006cc2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T10:06:25.553370Z",
     "iopub.status.busy": "2023-03-25T10:06:25.552585Z",
     "iopub.status.idle": "2023-03-25T13:31:21.261278Z",
     "shell.execute_reply": "2023-03-25T13:31:21.259755Z"
    },
    "papermill": {
     "duration": 12295.717695,
     "end_time": "2023-03-25T13:31:21.265457",
     "exception": false,
     "start_time": "2023-03-25T10:06:25.547762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:24<00:00, 20.51it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.13it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.96it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.71it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.30it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.47it/s]\n",
      "100%|██████████| 500/500 [00:26<00:00, 19.02it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.63it/s]\n",
      "100%|██████████| 500/500 [04:00<00:00,  2.08it/s]\n",
      "100%|██████████| 500/500 [04:01<00:00,  2.07it/s]\n",
      "100%|██████████| 500/500 [03:59<00:00,  2.09it/s]\n",
      "100%|██████████| 500/500 [03:56<00:00,  2.11it/s]\n",
      "100%|██████████| 500/500 [02:01<00:00,  4.10it/s]\n",
      "100%|██████████| 500/500 [02:02<00:00,  4.07it/s]\n",
      "100%|██████████| 500/500 [02:04<00:00,  4.03it/s]\n",
      "100%|██████████| 500/500 [02:02<00:00,  4.08it/s]\n",
      "100%|██████████| 500/500 [00:33<00:00, 14.96it/s]\n",
      "100%|██████████| 500/500 [00:54<00:00,  9.11it/s]\n",
      "100%|██████████| 500/500 [01:15<00:00,  6.64it/s]\n",
      "100%|██████████| 500/500 [01:56<00:00,  4.30it/s]\n",
      "100%|██████████| 500/500 [00:35<00:00, 14.16it/s]\n",
      "100%|██████████| 500/500 [00:59<00:00,  8.43it/s]\n",
      "100%|██████████| 500/500 [01:23<00:00,  5.96it/s]\n",
      "100%|██████████| 500/500 [02:08<00:00,  3.89it/s]\n",
      "100%|██████████| 500/500 [08:28<00:00,  1.02s/it]\n",
      "100%|██████████| 500/500 [16:45<00:00,  2.01s/it]\n",
      "100%|██████████| 500/500 [25:08<00:00,  3.02s/it]\n",
      "100%|██████████| 500/500 [33:21<00:00,  4.00s/it]\n",
      "100%|██████████| 500/500 [08:28<00:00,  1.02s/it]\n",
      "100%|██████████| 500/500 [16:47<00:00,  2.02s/it]\n",
      "100%|██████████| 500/500 [25:05<00:00,  3.01s/it]\n",
      "100%|██████████| 500/500 [33:31<00:00,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best arm is 20, best model is RandomForestClassifier(max_depth=5, n_estimators=50, random_state=0)\n",
      "KNeighborsClassifier(), entropy 0.8573784438836206, running time 0.02016094970703125\n",
      "KNeighborsClassifier(n_neighbors=15), entropy 0.48823275431585744, running time 0.02092872667312622\n",
      "KNeighborsClassifier(n_neighbors=25), entropy 0.5653357645218335, running time 0.02131120681762695\n",
      "KNeighborsClassifier(n_neighbors=35), entropy 0.6154464899710326, running time 0.02155689764022827\n",
      "KNeighborsClassifier(n_neighbors=45), entropy 0.6312098161154652, running time 0.020849319458007814\n",
      "KNeighborsClassifier(n_neighbors=55), entropy 0.6416978484210916, running time 0.02188170623779297\n",
      "KNeighborsClassifier(n_neighbors=65), entropy 0.6525717378145706, running time 0.02233941602706909\n",
      "KNeighborsClassifier(n_neighbors=75), entropy 0.6429523214170524, running time 0.02245058298110962\n",
      "LogisticRegression(C=1, random_state=0), entropy 0.6942695875865583, running time 0.44920317220687866\n",
      "LogisticRegression(C=2, random_state=0), entropy 0.7621006372263658, running time 0.4503557538986206\n",
      "LogisticRegression(C=1, fit_intercept=False, random_state=0), entropy 0.7177625430582283, running time 0.4461791534423828\n",
      "LogisticRegression(C=2, fit_intercept=False, random_state=0), entropy 0.7280867466245662, running time 0.4412064518928528\n",
      "LogisticRegression(C=1, penalty='none', random_state=0), entropy 2.4225748543093086, running time 0.21206147432327271\n",
      "LogisticRegression(C=2, penalty='none', random_state=0), entropy 2.4162371084939016, running time 0.21367200469970704\n",
      "LogisticRegression(C=1, fit_intercept=False, penalty='none', random_state=0), entropy 2.3993294363964264, running time 0.2164113426208496\n",
      "LogisticRegression(C=2, fit_intercept=False, penalty='none', random_state=0), entropy 2.4619626892838307, running time 0.21387477588653564\n",
      "RandomForestClassifier(max_depth=5, n_estimators=10, random_state=0), entropy 0.5150872295303192, running time 0.04871584367752075\n",
      "RandomForestClassifier(max_depth=5, n_estimators=20, random_state=0), entropy 0.4772104702070262, running time 0.09043839693069458\n",
      "RandomForestClassifier(max_depth=5, n_estimators=30, random_state=0), entropy 0.47030861690486747, running time 0.13116348934173583\n",
      "RandomForestClassifier(max_depth=5, n_estimators=50, random_state=0), entropy 0.4673081043090829, running time 0.2136899905204773\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=10,\n",
      "                       random_state=0), entropy 0.5345993229767741, running time 0.053100916385650634\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=20,\n",
      "                       random_state=0), entropy 0.4921918214907258, running time 0.09960913801193237\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=30,\n",
      "                       random_state=0), entropy 0.4743691513409109, running time 0.1476178798675537\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=50,\n",
      "                       random_state=0), entropy 0.46809440635796207, running time 0.23827815771102906\n",
      "AdaBoostClassifier(n_estimators=10, random_state=0), entropy 0.6174283501016068, running time 0.9976675038337708\n",
      "AdaBoostClassifier(n_estimators=20, random_state=0), entropy 0.6071255650742564, running time 1.9924477672576903\n",
      "AdaBoostClassifier(n_estimators=30, random_state=0), entropy 0.6128296713112902, running time 2.9987956185340883\n",
      "AdaBoostClassifier(n_estimators=40, random_state=0), entropy 0.6120352534511524, running time 3.9830864543914797\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=10, random_state=0), entropy 0.6165990898463709, running time 0.9977949357032776\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=20, random_state=0), entropy 0.560604722708793, running time 1.9965142693519593\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=30, random_state=0), entropy 0.5496235120684759, running time 2.9920947399139406\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=40, random_state=0), entropy 0.5511513473825185, running time 4.004301834106445\n",
      "23.799759870052338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell for quickly testing model\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.base import clone\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_list = [\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    KNeighborsClassifier(n_neighbors=15),\n",
    "    KNeighborsClassifier(n_neighbors=25),\n",
    "    KNeighborsClassifier(n_neighbors=35),\n",
    "    KNeighborsClassifier(n_neighbors=45),\n",
    "    KNeighborsClassifier(n_neighbors=55),\n",
    "    KNeighborsClassifier(n_neighbors=65),\n",
    "    KNeighborsClassifier(n_neighbors=75),\n",
    "    \n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=True, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=True, random_state=0, max_iter=100, C=2),\n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=False, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=False, random_state=0, max_iter=100, C=2),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=True, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=True, random_state=0, max_iter=100, C=2),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=False, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=False, random_state=0, max_iter=100, C=2),\n",
    "    \n",
    "    RandomForestClassifier(n_estimators=10, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=20, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=30, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=50, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=10, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=20, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=30, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=50, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    \n",
    "    AdaBoostClassifier(n_estimators=10, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=20, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=30, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=40, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=10, learning_rate=0.1, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=20, learning_rate=0.1, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=30, learning_rate=0.1, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=40, learning_rate=0.1, random_state=0),\n",
    "]\n",
    "\n",
    "def GetBestArm(model_list, n_ground_truth, dataset):\n",
    "    Match_Index_to_Model = dict()\n",
    "    for ii, model in enumerate(model_list):\n",
    "        Match_Index_to_Model[ii + 1] = model\n",
    "    cross_entropy_ = np.zeros((len(Match_Index_to_Model), n_ground_truth))\n",
    "    running_time_ = np.zeros((len(Match_Index_to_Model), n_ground_truth))\n",
    "    for arm_index in range(1, len(Match_Index_to_Model) + 1):\n",
    "        for exp_index in tqdm(range(n_ground_truth)):\n",
    "            # split the dataset with different random seed\n",
    "            new_random_state = np.random.randint(0, 2**31 - 1)\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(dataset[\"data\"], dataset[\"target\"], test_size=0.3, random_state=new_random_state)\n",
    "\n",
    "            t1 = time.time()\n",
    "            model = clone(Match_Index_to_Model[arm_index])\n",
    "            model.fit(X_train, Y_train)\n",
    "            y_test_predict_proba = model.predict_proba(X_test)\n",
    "            t2 = time.time()\n",
    "            \n",
    "            cross_entropy_[arm_index - 1, exp_index] = -log_loss(Y_test, y_test_predict_proba)\n",
    "            running_time_[arm_index - 1, exp_index] = t2 - t1\n",
    "            \n",
    "    cross_entropy_mean_ = np.mean(cross_entropy_, axis=1)\n",
    "    running_time_mean_ = np.mean(running_time_, axis=1)\n",
    "    best_arm = np.argmax(cross_entropy_mean_) + 1\n",
    "    print(f\"best arm is {best_arm}, best model is {model_list[best_arm-1].__str__()}\")\n",
    "    for ii, model in enumerate(model_list):\n",
    "        print(f\"{model.__str__()}, entropy {-cross_entropy_mean_[ii]}, running time {running_time_mean_[ii]}\")\n",
    "    return best_arm, Match_Index_to_Model, cross_entropy_, running_time_\n",
    "\n",
    "best_arm, Match_Index_to_Model, cross_entropy_, running_time_ = GetBestArm(\n",
    "    model_list=model_list, \n",
    "    n_ground_truth=500, \n",
    "    dataset=dataset\n",
    ")\n",
    "print(np.sum(np.mean(running_time_, axis=1)))\n",
    "\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8495f",
   "metadata": {
    "papermill": {
     "duration": 0.93277,
     "end_time": "2023-03-25T13:31:23.044379",
     "exception": false,
     "start_time": "2023-03-25T13:31:22.111609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12312.31357,
   "end_time": "2023-03-25T13:31:24.128064",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-25T10:06:11.814494",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
