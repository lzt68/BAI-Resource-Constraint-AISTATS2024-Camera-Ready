{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e52b18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:11:40.285336Z",
     "iopub.status.busy": "2023-03-18T13:11:40.284610Z",
     "iopub.status.idle": "2023-03-18T13:11:42.044865Z",
     "shell.execute_reply": "2023-03-18T13:11:42.043152Z"
    },
    "papermill": {
     "duration": 1.767592,
     "end_time": "2023-03-18T13:11:42.048366",
     "exception": false,
     "start_time": "2023-03-18T13:11:40.280774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of label -1 is 1000\n",
      "number of label 1 is 1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from agent import *\n",
    "from env import Env_Classifier_CrossEntropy\n",
    "from utils import Experiment_Classiflier\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "from sklearn.linear_model import LogisticRegression  # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "from sklearn.svm import SVC  # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn.ensemble import RandomForestClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.ensemble import AdaBoostClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "\n",
    "madelon = pd.read_csv(\"./madelon.csv\")\n",
    "data = madelon[madelon.columns[:-1]].values\n",
    "target = madelon[madelon.columns[-1]].values\n",
    "dataset = dict()\n",
    "dataset[\"data\"] = data\n",
    "dataset[\"target\"] = target\n",
    "\n",
    "index = dataset[\"target\"]==-1\n",
    "print(f\"number of label -1 is {np.sum(index)}\")\n",
    "index = dataset[\"target\"]==1\n",
    "print(f\"number of label 1 is {np.sum(index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e01bd851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T13:11:42.093702Z",
     "iopub.status.busy": "2023-03-18T13:11:42.093311Z",
     "iopub.status.idle": "2023-03-18T15:10:36.689415Z",
     "shell.execute_reply": "2023-03-18T15:10:36.688337Z"
    },
    "papermill": {
     "duration": 7134.603658,
     "end_time": "2023-03-18T15:10:36.692679",
     "exception": false,
     "start_time": "2023-03-18T13:11:42.089021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:35<00:00, 14.13it/s]\n",
      "100%|██████████| 500/500 [00:37<00:00, 13.39it/s]\n",
      "100%|██████████| 500/500 [00:36<00:00, 13.64it/s]\n",
      "100%|██████████| 500/500 [00:37<00:00, 13.33it/s]\n",
      "100%|██████████| 500/500 [00:38<00:00, 12.99it/s]\n",
      "100%|██████████| 500/500 [00:39<00:00, 12.51it/s]\n",
      "100%|██████████| 500/500 [00:40<00:00, 12.31it/s]\n",
      "100%|██████████| 500/500 [00:41<00:00, 12.01it/s]\n",
      "100%|██████████| 500/500 [01:18<00:00,  6.38it/s]\n",
      "100%|██████████| 500/500 [01:16<00:00,  6.50it/s]\n",
      "100%|██████████| 500/500 [01:14<00:00,  6.71it/s]\n",
      "100%|██████████| 500/500 [01:16<00:00,  6.51it/s]\n",
      "100%|██████████| 500/500 [01:17<00:00,  6.45it/s]\n",
      "100%|██████████| 500/500 [01:18<00:00,  6.37it/s]\n",
      "100%|██████████| 500/500 [01:16<00:00,  6.56it/s]\n",
      "100%|██████████| 500/500 [01:17<00:00,  6.47it/s]\n",
      "100%|██████████| 500/500 [00:52<00:00,  9.49it/s]\n",
      "100%|██████████| 500/500 [01:38<00:00,  5.10it/s]\n",
      "100%|██████████| 500/500 [02:22<00:00,  3.50it/s]\n",
      "100%|██████████| 500/500 [03:53<00:00,  2.14it/s]\n",
      "100%|██████████| 500/500 [00:58<00:00,  8.53it/s]\n",
      "100%|██████████| 500/500 [01:49<00:00,  4.57it/s]\n",
      "100%|██████████| 500/500 [02:40<00:00,  3.11it/s]\n",
      "100%|██████████| 500/500 [04:23<00:00,  1.90it/s]\n",
      "100%|██████████| 500/500 [04:15<00:00,  1.96it/s]\n",
      "100%|██████████| 500/500 [08:26<00:00,  1.01s/it]\n",
      "100%|██████████| 500/500 [13:04<00:00,  1.57s/it]\n",
      "100%|██████████| 500/500 [16:51<00:00,  2.02s/it]\n",
      "100%|██████████| 500/500 [04:15<00:00,  1.95it/s]\n",
      "100%|██████████| 500/500 [08:25<00:00,  1.01s/it]\n",
      "100%|██████████| 500/500 [12:37<00:00,  1.51s/it]\n",
      "100%|██████████| 500/500 [16:54<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best arm is 2, best model is KNeighborsClassifier(n_neighbors=15)\n",
      "KNeighborsClassifier(), entropy 1.1990018623740697, running time 0.05369347286224365\n",
      "KNeighborsClassifier(n_neighbors=15), entropy 0.5516399321157754, running time 0.055459813594818115\n",
      "KNeighborsClassifier(n_neighbors=25), entropy 0.5554227256481399, running time 0.056111196041107175\n",
      "KNeighborsClassifier(n_neighbors=35), entropy 0.5667594163036422, running time 0.05826449203491211\n",
      "KNeighborsClassifier(n_neighbors=45), entropy 0.5744467092859586, running time 0.05991172885894775\n",
      "KNeighborsClassifier(n_neighbors=55), entropy 0.5843701947646704, running time 0.06277630281448364\n",
      "KNeighborsClassifier(n_neighbors=65), entropy 0.5913861129310771, running time 0.06348921918869019\n",
      "KNeighborsClassifier(n_neighbors=75), entropy 0.5981026251609437, running time 0.06583350896835327\n",
      "LogisticRegression(C=1, random_state=0), entropy 1.0090203212077722, running time 0.140706374168396\n",
      "LogisticRegression(C=2, random_state=0), entropy 1.0208685836160105, running time 0.13869544553756713\n",
      "LogisticRegression(C=1, fit_intercept=False, random_state=0), entropy 1.0115194234490832, running time 0.13423912715911865\n",
      "LogisticRegression(C=2, fit_intercept=False, random_state=0), entropy 1.021366204665472, running time 0.13845946884155275\n",
      "LogisticRegression(C=1, penalty='none', random_state=0), entropy 1.012655849111273, running time 0.14030057764053344\n",
      "LogisticRegression(C=2, penalty='none', random_state=0), entropy 1.015602457206597, running time 0.1403372321128845\n",
      "LogisticRegression(C=1, fit_intercept=False, penalty='none', random_state=0), entropy 1.0220343276009975, running time 0.13690569019317628\n",
      "LogisticRegression(C=2, fit_intercept=False, penalty='none', random_state=0), entropy 1.0243598196092625, running time 0.13818847465515136\n",
      "RandomForestClassifier(max_depth=5, n_estimators=10, random_state=0), entropy 0.6398056922586711, running time 0.09605102396011353\n",
      "RandomForestClassifier(max_depth=5, n_estimators=20, random_state=0), entropy 0.6454521054954877, running time 0.18677320098876954\n",
      "RandomForestClassifier(max_depth=5, n_estimators=30, random_state=0), entropy 0.6442430701367992, running time 0.2761519203186035\n",
      "RandomForestClassifier(max_depth=5, n_estimators=50, random_state=0), entropy 0.6426389283781373, running time 0.45841929721832275\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=10,\n",
      "                       random_state=0), entropy 0.6397956790096733, running time 0.10797567319869995\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=20,\n",
      "                       random_state=0), entropy 0.6439652213562327, running time 0.209476026058197\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=30,\n",
      "                       random_state=0), entropy 0.6441801553364362, running time 0.3123155069351196\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=50,\n",
      "                       random_state=0), entropy 0.6426422968863394, running time 0.517893961429596\n",
      "AdaBoostClassifier(n_estimators=10, random_state=0), entropy 0.6816346818455893, running time 0.5017989439964294\n",
      "AdaBoostClassifier(n_estimators=20, random_state=0), entropy 0.6866972071665391, running time 1.0031822156906127\n",
      "AdaBoostClassifier(n_estimators=30, random_state=0), entropy 0.6885354439838302, running time 1.5589027190208435\n",
      "AdaBoostClassifier(n_estimators=40, random_state=0), entropy 0.6895197498813959, running time 2.0141188611984253\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=10, random_state=0), entropy 0.6650255886719293, running time 0.5029019637107849\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=20, random_state=0), entropy 0.6707830992026104, running time 1.0017884941101074\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=30, random_state=0), entropy 0.6747938111055812, running time 1.5053540506362915\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=40, random_state=0), entropy 0.6776644261205768, running time 2.0189544410705564\n",
      "13.855430424213411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell for quickly testing model\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.base import clone\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_list = [\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    KNeighborsClassifier(n_neighbors=15),\n",
    "    KNeighborsClassifier(n_neighbors=25),\n",
    "    KNeighborsClassifier(n_neighbors=35),\n",
    "    KNeighborsClassifier(n_neighbors=45),\n",
    "    KNeighborsClassifier(n_neighbors=55),\n",
    "    KNeighborsClassifier(n_neighbors=65),\n",
    "    KNeighborsClassifier(n_neighbors=75),\n",
    "    \n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=True, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=True, random_state=0, max_iter=100, C=2),\n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=False, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=False, random_state=0, max_iter=100, C=2),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=True, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=True, random_state=0, max_iter=100, C=2),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=False, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=False, random_state=0, max_iter=100, C=2),\n",
    "    \n",
    "    RandomForestClassifier(n_estimators=10, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=20, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=30, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=50, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=10, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=20, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=30, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=50, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    \n",
    "    AdaBoostClassifier(n_estimators=10, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=20, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=30, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=40, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=10, learning_rate=0.1, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=20, learning_rate=0.1, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=30, learning_rate=0.1, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=40, learning_rate=0.1, random_state=0),\n",
    "]\n",
    "\n",
    "def GetBestArm(model_list, n_ground_truth, dataset):\n",
    "    Match_Index_to_Model = dict()\n",
    "    for ii, model in enumerate(model_list):\n",
    "        Match_Index_to_Model[ii + 1] = model\n",
    "    cross_entropy_ = np.zeros((len(Match_Index_to_Model), n_ground_truth))\n",
    "    running_time_ = np.zeros((len(Match_Index_to_Model), n_ground_truth))\n",
    "    for arm_index in range(1, len(Match_Index_to_Model) + 1):\n",
    "        for exp_index in tqdm(range(n_ground_truth)):\n",
    "            # split the dataset with different random seed\n",
    "            new_random_state = np.random.randint(0, 2**31 - 1)\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(dataset[\"data\"], dataset[\"target\"], test_size=0.3, random_state=new_random_state)\n",
    "\n",
    "            t1 = time.time()\n",
    "            model = clone(Match_Index_to_Model[arm_index])\n",
    "            model.fit(X_train, Y_train)\n",
    "            y_test_predict_proba = model.predict_proba(X_test)\n",
    "            t2 = time.time()\n",
    "            \n",
    "            cross_entropy_[arm_index - 1, exp_index] = -log_loss(Y_test, y_test_predict_proba)\n",
    "            running_time_[arm_index - 1, exp_index] = t2 - t1\n",
    "            \n",
    "    cross_entropy_mean_ = np.mean(cross_entropy_, axis=1)\n",
    "    running_time_mean_ = np.mean(running_time_, axis=1)\n",
    "    best_arm = np.argmax(cross_entropy_mean_) + 1\n",
    "    print(f\"best arm is {best_arm}, best model is {model_list[best_arm-1].__str__()}\")\n",
    "    for ii, model in enumerate(model_list):\n",
    "        print(f\"{model.__str__()}, entropy {-cross_entropy_mean_[ii]}, running time {running_time_mean_[ii]}\")\n",
    "    return best_arm, Match_Index_to_Model, cross_entropy_, running_time_\n",
    "\n",
    "best_arm, Match_Index_to_Model, cross_entropy_, running_time_ = GetBestArm(\n",
    "    model_list=model_list, \n",
    "    n_ground_truth=500, \n",
    "    dataset=dataset\n",
    ")\n",
    "print(np.sum(np.mean(running_time_, axis=1)))\n",
    "\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110a9d0",
   "metadata": {
    "papermill": {
     "duration": 0.958958,
     "end_time": "2023-03-18T15:10:38.536457",
     "exception": false,
     "start_time": "2023-03-18T15:10:37.577499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7151.970059,
   "end_time": "2023-03-18T15:10:40.259117",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-18T13:11:28.289058",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
