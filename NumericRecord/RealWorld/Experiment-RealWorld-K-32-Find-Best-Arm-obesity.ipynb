{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4580e85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-27T06:42:49.326935Z",
     "iopub.status.busy": "2023-03-27T06:42:49.326243Z",
     "iopub.status.idle": "2023-03-27T06:42:50.741745Z",
     "shell.execute_reply": "2023-03-27T06:42:50.739656Z"
    },
    "papermill": {
     "duration": 1.421573,
     "end_time": "2023-03-27T06:42:50.744888",
     "exception": false,
     "start_time": "2023-03-27T06:42:49.323315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2111, 21)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from agent import *\n",
    "from env import Env_Classifier_CrossEntropy\n",
    "from utils import Experiment_Classiflier\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "from sklearn.linear_model import LogisticRegression  # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "from sklearn.svm import SVC  # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn.ensemble import RandomForestClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.ensemble import AdaBoostClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "\n",
    "dataset_ = pd.read_csv(\"./Obesity.csv\")\n",
    "data = dataset_[dataset_.drop(columns=[\"NObeyesdad\"]).columns].values\n",
    "target = dataset_[\"NObeyesdad\"].values\n",
    "dataset = dict()\n",
    "dataset[\"data\"] = data\n",
    "dataset[\"target\"] = target\n",
    "\n",
    "print(dataset_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74885cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-27T06:42:50.766667Z",
     "iopub.status.busy": "2023-03-27T06:42:50.766342Z",
     "iopub.status.idle": "2023-03-27T06:59:23.973944Z",
     "shell.execute_reply": "2023-03-27T06:59:23.971978Z"
    },
    "papermill": {
     "duration": 993.213223,
     "end_time": "2023-03-27T06:59:23.976198",
     "exception": false,
     "start_time": "2023-03-27T06:42:50.762975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:11<00:00, 43.61it/s]\n",
      "100%|██████████| 500/500 [00:11<00:00, 42.60it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 40.65it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 39.01it/s]\n",
      "100%|██████████| 500/500 [00:13<00:00, 37.36it/s]\n",
      "100%|██████████| 500/500 [00:14<00:00, 35.15it/s]\n",
      "100%|██████████| 500/500 [00:14<00:00, 35.17it/s]\n",
      "100%|██████████| 500/500 [00:15<00:00, 33.15it/s]\n",
      "100%|██████████| 500/500 [00:40<00:00, 12.33it/s]\n",
      "100%|██████████| 500/500 [00:40<00:00, 12.26it/s]\n",
      "100%|██████████| 500/500 [00:37<00:00, 13.40it/s]\n",
      "100%|██████████| 500/500 [00:37<00:00, 13.45it/s]\n",
      "100%|██████████| 500/500 [00:40<00:00, 12.31it/s]\n",
      "100%|██████████| 500/500 [00:40<00:00, 12.26it/s]\n",
      "100%|██████████| 500/500 [00:37<00:00, 13.35it/s]\n",
      "100%|██████████| 500/500 [00:37<00:00, 13.42it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 40.83it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.74it/s]\n",
      "100%|██████████| 500/500 [00:33<00:00, 14.81it/s]\n",
      "100%|██████████| 500/500 [00:54<00:00,  9.10it/s]\n",
      "100%|██████████| 500/500 [00:14<00:00, 35.08it/s]\n",
      "100%|██████████| 500/500 [00:27<00:00, 18.27it/s]\n",
      "100%|██████████| 500/500 [00:40<00:00, 12.38it/s]\n",
      "100%|██████████| 500/500 [01:06<00:00,  7.54it/s]\n",
      "100%|██████████| 500/500 [00:16<00:00, 31.20it/s]\n",
      "100%|██████████| 500/500 [00:30<00:00, 16.31it/s]\n",
      "100%|██████████| 500/500 [00:45<00:00, 11.07it/s]\n",
      "100%|██████████| 500/500 [01:00<00:00,  8.32it/s]\n",
      "100%|██████████| 500/500 [00:15<00:00, 31.56it/s]\n",
      "100%|██████████| 500/500 [00:30<00:00, 16.34it/s]\n",
      "100%|██████████| 500/500 [00:45<00:00, 11.08it/s]\n",
      "100%|██████████| 500/500 [01:00<00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best arm is 4, best model is KNeighborsClassifier(n_neighbors=35)\n",
      "KNeighborsClassifier(), entropy 1.4282596677462256, running time 0.020610714435577392\n",
      "KNeighborsClassifier(n_neighbors=15), entropy 0.8076407710572835, running time 0.021264644622802736\n",
      "KNeighborsClassifier(n_neighbors=25), entropy 0.7334286480191543, running time 0.021996756076812743\n",
      "KNeighborsClassifier(n_neighbors=35), entropy 0.7181393793749339, running time 0.023150825023651123\n",
      "KNeighborsClassifier(n_neighbors=45), entropy 0.7345972331280052, running time 0.024248215675354005\n",
      "KNeighborsClassifier(n_neighbors=55), entropy 0.7546210076750651, running time 0.02574489164352417\n",
      "KNeighborsClassifier(n_neighbors=65), entropy 0.7758838082309837, running time 0.026076392650604248\n",
      "KNeighborsClassifier(n_neighbors=75), entropy 0.7916558549203006, running time 0.027808285236358643\n",
      "LogisticRegression(C=1, random_state=0), entropy 0.8616643147096255, running time 0.07862513828277588\n",
      "LogisticRegression(C=2, random_state=0), entropy 0.8602406495988995, running time 0.07902537202835083\n",
      "LogisticRegression(C=1, fit_intercept=False, random_state=0), entropy 0.8686935648986932, running time 0.07215017652511596\n",
      "LogisticRegression(C=2, fit_intercept=False, random_state=0), entropy 0.872042423126503, running time 0.0719349398612976\n",
      "LogisticRegression(C=1, penalty='none', random_state=0), entropy 0.8630347106404562, running time 0.07874812984466553\n",
      "LogisticRegression(C=2, penalty='none', random_state=0), entropy 0.8625234437198089, running time 0.07907914447784424\n",
      "LogisticRegression(C=1, fit_intercept=False, penalty='none', random_state=0), entropy 0.8732920733880116, running time 0.07244835901260376\n",
      "LogisticRegression(C=2, fit_intercept=False, penalty='none', random_state=0), entropy 0.8724542843070812, running time 0.07204511165618896\n",
      "RandomForestClassifier(max_depth=5, n_estimators=10, random_state=0), entropy 0.817351493048129, running time 0.022678749561309816\n",
      "RandomForestClassifier(max_depth=5, n_estimators=20, random_state=0), entropy 0.8191717347113953, running time 0.04389581966400147\n",
      "RandomForestClassifier(max_depth=5, n_estimators=30, random_state=0), entropy 0.7956827245961633, running time 0.06505967235565185\n",
      "RandomForestClassifier(max_depth=5, n_estimators=50, random_state=0), entropy 0.7866094968449103, running time 0.10653626298904419\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=10,\n",
      "                       random_state=0), entropy 0.7946764784397299, running time 0.026603742122650147\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=20,\n",
      "                       random_state=0), entropy 0.8006271568995731, running time 0.05238146066665649\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=30,\n",
      "                       random_state=0), entropy 0.7751512807242109, running time 0.07836139822006226\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=50,\n",
      "                       random_state=0), entropy 0.7687546707287176, running time 0.12917906856536865\n",
      "AdaBoostClassifier(n_estimators=10, random_state=0), entropy 1.5817927304650334, running time 0.03013980197906494\n",
      "AdaBoostClassifier(n_estimators=20, random_state=0), entropy 1.5109010111443895, running time 0.0589249587059021\n",
      "AdaBoostClassifier(n_estimators=30, random_state=0), entropy 1.4766382086637417, running time 0.08790542554855346\n",
      "AdaBoostClassifier(n_estimators=40, random_state=0), entropy 1.4656510095661879, running time 0.11681999826431275\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=10, random_state=0), entropy 1.366763468919982, running time 0.02981311511993408\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=20, random_state=0), entropy 1.453139570631482, running time 0.058827260971069335\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=30, random_state=0), entropy 1.4737130842585433, running time 0.08783969354629517\n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=40, random_state=0), entropy 1.4843910994959388, running time 0.11682869052886963\n",
      "1.9067522158622743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell for quickly testing model\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.base import clone\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_list = [\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    KNeighborsClassifier(n_neighbors=15),\n",
    "    KNeighborsClassifier(n_neighbors=25),\n",
    "    KNeighborsClassifier(n_neighbors=35),\n",
    "    KNeighborsClassifier(n_neighbors=45),\n",
    "    KNeighborsClassifier(n_neighbors=55),\n",
    "    KNeighborsClassifier(n_neighbors=65),\n",
    "    KNeighborsClassifier(n_neighbors=75), \n",
    "    \n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=True, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=True, random_state=0, max_iter=100, C=2),\n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=False, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"l2\", fit_intercept=False, random_state=0, max_iter=100, C=2),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=True, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=True, random_state=0, max_iter=100, C=2),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=False, random_state=0, max_iter=100, C=1),\n",
    "    LogisticRegression(penalty=\"none\", fit_intercept=False, random_state=0, max_iter=100, C=2),\n",
    "    \n",
    "    RandomForestClassifier(n_estimators=10, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=20, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=30, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=50, criterion=\"gini\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=10, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=20, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=30, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=50, criterion=\"entropy\", max_depth=5, random_state=0),\n",
    "    \n",
    "    AdaBoostClassifier(n_estimators=10, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=20, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=30, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=40, learning_rate=1.0, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=10, learning_rate=0.1, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=20, learning_rate=0.1, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=30, learning_rate=0.1, random_state=0),\n",
    "    AdaBoostClassifier(n_estimators=40, learning_rate=0.1, random_state=0),\n",
    "]\n",
    "\n",
    "def GetBestArm(model_list, n_ground_truth, dataset):\n",
    "    Match_Index_to_Model = dict()\n",
    "    for ii, model in enumerate(model_list):\n",
    "        Match_Index_to_Model[ii + 1] = model\n",
    "    cross_entropy_ = np.zeros((len(Match_Index_to_Model), n_ground_truth))\n",
    "    running_time_ = np.zeros((len(Match_Index_to_Model), n_ground_truth))\n",
    "    for arm_index in range(1, len(Match_Index_to_Model) + 1):\n",
    "        for exp_index in tqdm(range(n_ground_truth)):\n",
    "            # split the dataset with different random seed\n",
    "            new_random_state = np.random.randint(0, 2**31 - 1)\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(dataset[\"data\"], dataset[\"target\"], test_size=0.3, random_state=new_random_state)\n",
    "\n",
    "            t1 = time.time()\n",
    "            model = clone(Match_Index_to_Model[arm_index])\n",
    "            model.fit(X_train, Y_train)\n",
    "            y_test_predict_proba = model.predict_proba(X_test)\n",
    "            t2 = time.time()\n",
    "            \n",
    "            cross_entropy_[arm_index - 1, exp_index] = -log_loss(Y_test, y_test_predict_proba)\n",
    "            running_time_[arm_index - 1, exp_index] = t2 - t1\n",
    "            \n",
    "    cross_entropy_mean_ = np.mean(cross_entropy_, axis=1)\n",
    "    running_time_mean_ = np.mean(running_time_, axis=1)\n",
    "    best_arm = np.argmax(cross_entropy_mean_) + 1\n",
    "    print(f\"best arm is {best_arm}, best model is {model_list[best_arm-1].__str__()}\")\n",
    "    for ii, model in enumerate(model_list):\n",
    "        print(f\"{model.__str__()}, entropy {-cross_entropy_mean_[ii]}, running time {running_time_mean_[ii]}\")\n",
    "    return best_arm, Match_Index_to_Model, cross_entropy_, running_time_\n",
    "\n",
    "best_arm, Match_Index_to_Model, cross_entropy_, running_time_ = GetBestArm(\n",
    "    model_list=model_list, \n",
    "    n_ground_truth=500, \n",
    "    dataset=dataset\n",
    ")\n",
    "print(np.sum(np.mean(running_time_, axis=1)))\n",
    "\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4795588",
   "metadata": {
    "papermill": {
     "duration": 0.428417,
     "end_time": "2023-03-27T06:59:24.884021",
     "exception": false,
     "start_time": "2023-03-27T06:59:24.455604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1005.571475,
   "end_time": "2023-03-27T06:59:26.124008",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-27T06:42:40.552533",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
